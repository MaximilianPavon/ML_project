{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.loadtxt(open(\"data/train_data.csv\", \"rb\"), delimiter=\",\", skiprows=1)\n",
    "train_labels = np.loadtxt(open(\"data/train_labels.csv\", \"rb\"), delimiter=\",\", skiprows=1)\n",
    "test_data = np.loadtxt(open(\"data/test_data.csv\", \"rb\"), delimiter=\",\", skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_data_stand = scaler.fit_transform(train_data)\n",
    "test_data_stand = scaler.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1, max_iter=2000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=2000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=True,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(clf.predict(test_data) != 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPRegressor(alpha=0.001, hidden_layer_sizes = (30,50,25), max_iter = 50000, activation = 'logistic', verbose = 'True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 4.16765784\n",
      "Iteration 2, loss = 3.29439058\n",
      "Iteration 3, loss = 3.11175446\n",
      "Iteration 4, loss = 3.08343846\n",
      "Iteration 5, loss = 3.05828652\n",
      "Iteration 6, loss = 3.01610639\n",
      "Iteration 7, loss = 2.96466533\n",
      "Iteration 8, loss = 2.90433172\n",
      "Iteration 9, loss = 2.84219189\n",
      "Iteration 10, loss = 2.77371261\n",
      "Iteration 11, loss = 2.73374565\n",
      "Iteration 12, loss = 2.67232675\n",
      "Iteration 13, loss = 2.62071140\n",
      "Iteration 14, loss = 2.57653556\n",
      "Iteration 15, loss = 2.54894319\n",
      "Iteration 16, loss = 2.53205420\n",
      "Iteration 17, loss = 2.50569313\n",
      "Iteration 18, loss = 2.53116452\n",
      "Iteration 19, loss = 2.52490728\n",
      "Iteration 20, loss = 2.52018005\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "a = clf.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1074"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.round(y_pred) == train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg = LogisticRegression(multi_class='ovr', penalty='l1',tol=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.1,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg.fit(train_data_stand, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74094452086198992"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg.score(train_data_stand,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.,  1.,  1., ...,  1.,  3.,  1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogReg.predict(test_data_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(train_data_stand, train_labels, test_size=0.33, random_state=42)\n",
    "\n",
    "Ytrain = Ytrain.astype(int)\n",
    "Ytest = Ytest.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from theano import tensor as T\n",
    "import numpy as np\n",
    "import theano\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotmodelfit(Xtrain,\n",
    "                 Ytrain,\n",
    "                 pred_train,\n",
    "                 nnact,\n",
    "                 X1grid,\n",
    "                 X2grid,\n",
    "                 pred_grid,\n",
    "                 cost_train_vec,\n",
    "                 cost_test_vec):\n",
    "    '''method\n",
    "    Inputs :\n",
    "    Xtrain, Ytrain        : N x D, N x 1 : traning datasets\n",
    "    X1grid, X2grid        : G x G, G x G : grid locations as test dataset\n",
    "    pred_train, pred_grid : N x 1, G x 1: model predictions on training dataset and grid dataset\n",
    "    cost_train, cost_test   : num_iter x 1, num_iter x 1 : error across iterations on training and test set\n",
    "    nnact                 : list of activation values in the hidden layer\n",
    "    '''\n",
    "\n",
    "    mt.rcParams['figure.figsize'] = (8, 6)\n",
    "    norm = mt.colors.Normalize(vmin=0., vmax=1.)\n",
    "\n",
    "    nh = [f.shape[1] for f in nnact]\n",
    "    nhiddenl = len(nh)\n",
    "\n",
    "    fig = plt.figure(num=122)\n",
    "\n",
    "    # gs for main plot\n",
    "    gs0 = gridspec.GridSpec(1, 2)\n",
    "    gs00 = gridspec.GridSpecFromSubplotSpec(2, 1, subplot_spec=gs0[0, 0])\n",
    "\n",
    "    # gs for hidden layers\n",
    "    gs1 = gridspec.GridSpecFromSubplotSpec(1, nhiddenl, subplot_spec=gs0[0, 1])\n",
    "\n",
    "    subgs = []\n",
    "    for i in np.arange(nhiddenl):\n",
    "        subgs.append(\n",
    "            gridspec.GridSpecFromSubplotSpec(nh[i], 1, subplot_spec=gs1[0, i]))\n",
    "\n",
    "    # ax for main\n",
    "    ax_00 = fig.add_subplot(gs00[0, 0])  #, adjustable='box-forced'\n",
    "    ax_00.scatter(\n",
    "        Xtrain[Ytrain == 1, 0],\n",
    "        Xtrain[Ytrain == 1, 1],\n",
    "        c=\"#ff9900\",\n",
    "        label=\"class 1\",\n",
    "        s=15,\n",
    "        alpha=0.8)\n",
    "    ax_00.scatter(\n",
    "        Xtrain[Ytrain == 0, 0],\n",
    "        Xtrain[Ytrain == 0, 1],\n",
    "        c=\"#02275a\",\n",
    "        label=\"class 0\",\n",
    "        s=15,\n",
    "        alpha=0.8)\n",
    "    ax_00.contourf(X1grid, X2grid, pred_grid, alpha=0.3)\n",
    "    ax_00.legend()\n",
    "    ax_00.set_title(\"model fit\")\n",
    "\n",
    "    ax_01 = fig.add_subplot(gs00[1, 0])  #, adjustable='box-forced'\n",
    "    ax_01.plot(\n",
    "        np.arange(cost_train_vec.shape[0]),\n",
    "        cost_train_vec,\n",
    "        c=\"#27ae61\",\n",
    "        label=\"train\")\n",
    "    ax_01.plot(\n",
    "        np.arange(cost_test_vec.shape[0]),\n",
    "        cost_test_vec,\n",
    "        c=\"#c1392b\",\n",
    "        label=\"test\")\n",
    "    ax_01.set_xlabel(\"iterations\")\n",
    "    ax_01.set_ylabel(\"cost function\")\n",
    "    ax_01.set_title(\"cost function across iterations\")\n",
    "    ax_01.legend()\n",
    "\n",
    "    axhl = []\n",
    "\n",
    "    # nested list for hidden layer activations\n",
    "    for hlayer in np.arange(nhiddenl):\n",
    "        axnn = []\n",
    "        for hnn in np.arange(nh[hlayer]):\n",
    "            ax = fig.add_subplot(subgs[hlayer][hnn, 0], aspect='equal')\n",
    "            ax.scatter(\n",
    "                Xtrain[:, 0],\n",
    "                Xtrain[:, 1],\n",
    "                c=nnact[hlayer][:, hnn],\n",
    "                cmap=\"RdBu\",\n",
    "                s=5,\n",
    "                norm=norm)\n",
    "            ax.xaxis.set_ticks([])\n",
    "            ax.yaxis.set_ticks([])\n",
    "            if hnn == 0:\n",
    "                ax.set_title(\"activations \" + \"\\n\" + \"in layer \" +\n",
    "                             str(hlayer + 1))\n",
    "            axnn.append(ax)\n",
    "        axhl.append(axnn)\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassificationTwoHiddenLayerNN(Xtrain,\n",
    "                                  Ytrain,\n",
    "                                  Xtest,\n",
    "                                  Ytest,\n",
    "                                  nn1=4,\n",
    "                                  nn2=3,\n",
    "                                  nnout=10,\n",
    "                                  training_steps=50000,\n",
    "                                  alpha=0.2):\n",
    "    '''\n",
    "    Input:\n",
    "    Xtrain   : N x D    : traning set features\n",
    "    Ytrian   : N x 1    : training set target\n",
    "    Xtest    : M x D    : test set feaures\n",
    "    Ytest    : M x 1    : test set target\n",
    "    nn1      : scalar   : no. of neurons to be used in first hidden layer\n",
    "    nn2      : scalar   : no. of neurons to be used in second hidden layer\n",
    "    training_steps : scalar : no. of training iteration steps\n",
    "    alpha    : scalar   : learning rate\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    print(\"*** running ***\")\n",
    " \n",
    "    # define input and output variables in theano\n",
    "    x = T.matrix('x')\n",
    "    y = T.vector('y')\n",
    "    xdim = Xtrain.shape[1]  # number of features in the data\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##########################################################\n",
    "    ################### add your code here ###################\n",
    "    ##########################################################\n",
    "            \n",
    "    # HINT : FOR WEIGHTS USE RANDOM STANDRD GAUSSIAN INITIALIZATION\n",
    "    #      : FOR BIAS USE ZERO INITIALIZATION\n",
    "    \n",
    "    # layer 01 parameter declaration & initialization (weights/bias)\n",
    "    np.random.seed(1232)\n",
    "    w_1 = theano.shared(np.random.randn(xdim, nn1), name='w_1')\n",
    "    b_1 = theano.shared(np.zeros((nn1,)), name='b_1')\n",
    "\n",
    "    # layer 02 parameter declaration & initialization (weights/bias) \n",
    "    np.random.seed(1232)\n",
    "    w_2 = theano.shared(np.random.randn(nn1, nn2), name='w_2')\n",
    "    b_2 = theano.shared(np.zeros((nn2,)), name='b_2')\n",
    "\n",
    "    # output layer parameter declaration & initialization (weights/bias) \n",
    "    np.random.seed(1232)\n",
    "    w_out = theano.shared(np.random.randn(nn2,nnout), name='w_out')\n",
    "    b_out = theano.shared(np.zeros((nnout,)), name='b_out')\n",
    "\n",
    "    # hidden layer output\n",
    "    h_out_1 = theano.tensor.nnet.sigmoid(T.dot(x, w_1) + b_1)\n",
    "    h_out_2 = theano.tensor.nnet.sigmoid(T.dot(h_out_1, w_2) + b_2)\n",
    "\n",
    "    # perceptron predictions\n",
    "    p_y_given_x = T.nnet.softmax(T.dot(h_out_2, w_out) + b_out)\n",
    "    y_pred = T.argmax(p_y_given_x, axis=1)\n",
    "\n",
    "    # cross-entropy as cost function\n",
    "    #cost   = T.nnet.binary_crossentropy(y_pred, y).mean()\n",
    "    \n",
    "    print(\"##########################################################\")\n",
    "    print(T.arange(y.shape[0]))\n",
    "    print(\"##########################################################\")\n",
    "    print( y.shape.eval())\n",
    "\n",
    "    cost   = -T.mean(T.log(p_y_given_x)[T.arange(y.shape[0]), y])\n",
    "\n",
    "    # gradient computation\n",
    "    gw_1, gb_1, gw_2, gb_2, gw_out, gb_out = T.grad(cost, [w_1, b_1,w_2, b_2, w_out, b_out])\n",
    "    \n",
    "    updates  =  [(w_1, w_1 - alpha * gw_1), \n",
    "             (b_1, b_1 - alpha * gb_1),\n",
    "             (w_2, w_2 - alpha * gw_2),\n",
    "             (b_2, b_2 - alpha * gb_2),\n",
    "             (w_out, w_out - alpha * gw_out), \n",
    "             (b_out, b_out - alpha * gb_out)] \n",
    "    \n",
    "        \n",
    "    # train_model theano function\n",
    "    # Note : outputs should return following in order\n",
    "    #      : [prediction vector, error/cost scalar,\n",
    "    #        1st hidden layer activation vector, 2nd hidden layer activation vector]\n",
    "    train_model = theano.function(\n",
    "             inputs  = [x,y],\n",
    "             outputs = [y_pred, cost, h_out_1, h_out_2],\n",
    "             updates = updates\n",
    "            )\n",
    "    \n",
    "\n",
    "    # function \n",
    "    # compute prediction on unseen test data\n",
    "    # Input   : x, y are intput, target vectors respectively\n",
    "    # Output  :  list of predictions\n",
    "    predict_model = theano.function(inputs=[x], outputs=[y_pred])\n",
    "    \n",
    "    # function \n",
    "    # compute cost on test data\n",
    "    # Input   : x, y are intput, target vectors respectively\n",
    "    # Output  : scalar cost\n",
    "    cost_function = theano.function(inputs=[x,y], outputs=cost)\n",
    "    \n",
    "\n",
    "    ##########################################################\n",
    "    ###################        end         ###################\n",
    "    ##########################################################\n",
    "        \n",
    "        \n",
    "        \n",
    "    # accumulate error over iterations on traning and test set in a vector\n",
    "    cost_train_vec = np.array([])\n",
    "    cost_test_vec = np.array([])\n",
    "\n",
    "    # training iterations begin\n",
    "    for i in np.arange(training_steps):\n",
    "        \n",
    "        # get predictions, cost, activation values \n",
    "        # on the training set\n",
    "        # pred_train - vector - predictions on training data\n",
    "        # cost_train  - scalar - cost/error for the current parameter value\n",
    "        # nactivation- vector - activation function from the hidden layer\n",
    "        pred_train, cost_train, nactivation1, nactivation2 = train_model(\n",
    "            Xtrain, Ytrain)\n",
    "        cost_train_vec = np.append(cost_train_vec, cost_train)\n",
    "            \n",
    "        # get predictions, cost on test set\n",
    "        pred_test = predict_model(Xtest)\n",
    "        cost_test = cost_function(Xtest,Ytest)\n",
    "        cost_test_vec = np.append(cost_test_vec, cost_test)\n",
    "        \n",
    "        # printing\n",
    "        if i % 10000 == 0:\n",
    "            print(\"Iteration %6s -- \"%i,'Training cost: ',\"%4.4f\"%cost_train)\n",
    "\n",
    "    print(\"final train set cost : %.4f\"%cost_train)\n",
    "    print(\"final test set cost  : %.4f\"%cost_test)\n",
    "    \n",
    "    # compute classification accuracies\n",
    "    train_predictions = (np.round(predict_model(Xtrain)).reshape((1,-1)))\n",
    "    train_accuracy = np.mean(train_predictions == Ytrain)\n",
    "    print(\"final train set classification accuracy : %.4f\"%train_accuracy)\n",
    "    \n",
    "    test_predictions = np.round(pred_test).reshape((1,-1))\n",
    "    test_accuracy = np.mean(test_predictions == Ytest)\n",
    "    print(\"final test set classification accuracy : %.4f\"%test_accuracy)\n",
    "    \n",
    "    # for the final model, plot model fit and activations\n",
    "    # on a grid\n",
    "    X1grid, X2grid = np.meshgrid(\n",
    "        np.linspace(-2, 3, 100), np.linspace(-1.7, 2, 100))\n",
    "    pred_grid = predict_model(\n",
    "        np.transpose(np.array([X1grid.flatten(), X2grid.flatten()])))\n",
    "    pred_grid = np.array(pred_grid)\n",
    "    pred_grid = pred_grid.reshape(X1grid.shape)\n",
    "\n",
    "    plotmodelfit(Xtrain, Ytrain, pred_train,\n",
    "                 [nactivation1, nactivation2],\n",
    "                 X1grid, X2grid, pred_grid,\n",
    "                 cost_train_vec, cost_test_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** running ***\n",
      "##########################################################\n",
      "ARange{dtype='int64'}.0\n",
      "##########################################################\n"
     ]
    },
    {
     "ename": "MissingInputError",
     "evalue": "Input 0 of the graph (indices start from 0), used to compute Shape(y), was not provided and not given a value. Use the Theano flag exception_verbosity='high', for more information on this error. \nBacktrace when that variable is created:\n\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-84-12661518298d>\", line 2, in <module>\n    Xtrain, Ytrain, Xtest, Ytest, nn1=3, nn2=2, nnout=10, training_steps=5000)\n  File \"<ipython-input-83-2a2ded0a3713>\", line 27, in ClassificationTwoHiddenLayerNN\n    y = T.vector('y')\n\n\nBacktrace when the variable is created:\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-84-12661518298d>\", line 2, in <module>\n    Xtrain, Ytrain, Xtest, Ytest, nn1=3, nn2=2, nnout=10, training_steps=5000)\n  File \"<ipython-input-83-2a2ded0a3713>\", line 27, in ClassificationTwoHiddenLayerNN\n    y = T.vector('y')\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingInputError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-12661518298d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m ClassificationTwoHiddenLayerNN(\n\u001b[0;32m----> 2\u001b[0;31m     Xtrain, Ytrain, Xtest, Ytest, nn1=3, nn2=2, nnout=10, training_steps=5000)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-83-2a2ded0a3713>\u001b[0m in \u001b[0;36mClassificationTwoHiddenLayerNN\u001b[0;34m(Xtrain, Ytrain, Xtest, Ytest, nn1, nn2, nnout, training_steps, alpha)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mcost\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_y_given_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/theano/gof/graph.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, inputs_to_values)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_to_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_cache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs_to_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/theano/compile/function.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[1;32m    324\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                    output_keys=output_keys)\n\u001b[0m\u001b[1;32m    327\u001b[0m     \u001b[0;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;31m# borrowed used defined inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/theano/compile/pfunc.py\u001b[0m in \u001b[0;36mpfunc\u001b[0;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m    484\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                          output_keys=output_keys)\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36morig_function\u001b[0;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[1;32m   1792\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1793\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1794\u001b[0;31m                    \u001b[0moutput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1795\u001b[0m             defaults)\n\u001b[1;32m   1796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph, output_keys)\u001b[0m\n\u001b[1;32m   1444\u001b[0m             \u001b[0;31m# OUTPUT VARIABLES)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m             fgraph, additional_outputs = std_fgraph(inputs, outputs,\n\u001b[0;32m-> 1446\u001b[0;31m                                                     accept_inplace)\n\u001b[0m\u001b[1;32m   1447\u001b[0m             \u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36mstd_fgraph\u001b[0;34m(input_specs, output_specs, accept_inplace)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     fgraph = gof.fg.FunctionGraph(orig_inputs, orig_outputs,\n\u001b[0;32m--> 177\u001b[0;31m                                   update_mapping=update_mapping)\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/theano/gof/fg.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, features, clone, update_mapping)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__import_r__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"init\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/theano/gof/fg.py\u001b[0m in \u001b[0;36m__import_r__\u001b[0;34m(self, variable, reason)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0;31m# Imports the owners of the variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         elif (variable.owner is None and\n\u001b[1;32m    353\u001b[0m                 \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/theano/gof/fg.py\u001b[0m in \u001b[0;36m__import__\u001b[0;34m(self, apply_node, check, reason)\u001b[0m\n\u001b[1;32m    395\u001b[0m                                      % (node.inputs.index(r), str(node)))\n\u001b[1;32m    396\u001b[0m                         \u001b[0merror_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mget_variable_trace_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mMissingInputError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingInputError\u001b[0m: Input 0 of the graph (indices start from 0), used to compute Shape(y), was not provided and not given a value. Use the Theano flag exception_verbosity='high', for more information on this error. \nBacktrace when that variable is created:\n\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-84-12661518298d>\", line 2, in <module>\n    Xtrain, Ytrain, Xtest, Ytest, nn1=3, nn2=2, nnout=10, training_steps=5000)\n  File \"<ipython-input-83-2a2ded0a3713>\", line 27, in ClassificationTwoHiddenLayerNN\n    y = T.vector('y')\n\n\nBacktrace when the variable is created:\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/anaconda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-84-12661518298d>\", line 2, in <module>\n    Xtrain, Ytrain, Xtest, Ytest, nn1=3, nn2=2, nnout=10, training_steps=5000)\n  File \"<ipython-input-83-2a2ded0a3713>\", line 27, in ClassificationTwoHiddenLayerNN\n    y = T.vector('y')\n"
     ]
    }
   ],
   "source": [
    "ClassificationTwoHiddenLayerNN(\n",
    "    Xtrain, Ytrain, Xtest, Ytest, nn1=3, nn2=2, nnout=10, training_steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 10,  6, ...,  2,  5,  1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
