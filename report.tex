\documentclass[12pt,a4paper,twocolumn]{article}

\usepackage[english]{babel} 		%% englische Sprache

\usepackage[latin1,applemac]{inputenc}	%% deutsche Umlaute wie normale
 					%% Buchstaben verwenden 
 					%% (ansonsten muesste ‰ durch a getippt werden)
\usepackage{a4wide} 			%% kleinere Seitenränder

\usepackage{amssymb,amsthm,amsfonts, amsmath}
								%% diverse Matheerweiterungen, z.B. \implies
 								%% diverse Matheerweiterungen, z.B. \mathbb{R}
%\usepackage{stmaryrd} 			%% weitere Symbole
\usepackage{epsfig} 			%% um eps-Dateien einzubinden (\epsfig{file=...})
\usepackage{longtable} 			%% fuer Tabellen ueber mehrere Seiten
\usepackage{color}
\usepackage{hyperref}
\usepackage{dsfont}
\usepackage{caption}

\title{ \textit{Some super concise and informative title} \\ Data Analysis Project for \\ \textit{Machine Learning: Basic Principles}}
%\author{Héctor Laria Mantecón and Maximilian Proll}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}

\textit{
Precise summary of the whole report, previews the contents and results. Must be a single paragraph between 100 and 200 words.
}

\end{abstract}

\section{Introduction}

\textit{
Background, problem statement, motivation, many references, description of contents. Introduces the reader to the topic and the broad context within which your research/project fits
\begin{itemize}
\item What do you hope to learn from the project?
\item What question is being addressed?
\item Why is this task important? (motivation)
\end{itemize}
Keep it short (half to 1 page).
}

\section{Data analysis}
This competition is performed on two datasets, a training and a test dataset with $4.363$ resp. $6.544$ songs. Each dataset has a total of $264$ features, which will be used for predicting one of $10$ classes. The features con be grouped into the 3 main components of music: timbre, pitch and rhythm. The $10$ classes are:  Pop Rock, Electronic, Rap, Jazz, Latin, R\&B, International, Country, Reggae and Blues.

In order to better visualise the training data we performed the \textit{t-Distributed Stochastic Neighbor Embedding} (\textbf{t-SNE}) with $3$ remaining dimensions. The result of this award-winning embedding is shown below:

\begin{center}
\includegraphics[width=\linewidth]{report_files/TSNE_data.png}
\end{center}

It is also important to know the distribution of the given training dataset. The distribution is shown in the following picture:

\begin{center}
\includegraphics[width=\linewidth]{report_files/Class_distribution.png}
\end{center}

This distribution shows very clearly that the training data is skewed, which means that the predictor will be able to generalise better for the majority classes and worse for those classes that have not many samples representing them.

%in case we need to fill more space we could add a boxplot of the 264 features.

%\textit{
%Briefly describe data (class distribution, dimensionality) and how will it affect classification. Visualize the data. Don’t focus too much on the meaning of the features, unless you want to.
%\begin{itemize}
%\item Include histograms showing class distribution.
%\end{itemize}
%}

\section{Methods and experiments}
\subsection{Overall approach}

To achieve best overall results we tried various machine learning techniques ranging from logistic regression (LogReg) and support vector machines (SVM) to naïve Bayes classifiers (NB) and neural networks (NN). Common for all machine learning techniques was, that we first standardised the training as well as the test data prior to performing any analysis. This step is crucial as it helps to reduce multicollinearity within the data and helps to improve the generalisation. This behaviour is backed up by comparing the accuracy of the prediction of the training data without standardisation ($p$) and with standardisation ($p_{st}$), which is summarised in table \ref{tab:accuracystandard}.

\begin{table}
\centering
\begin{tabular}{c|c|c}
ML technique & $p$ & $p_{st}$ \\ \hline
LogReg & 0.66 & 0.74 \\
SVM & 0.03 & 0.22 \\
NB & 0.46 & 0.52 \\
NN & 0.55 & 0.73
\end{tabular}
\caption{Comparison of accuracy of training data without standardisation and with  standardisation}
\label{tab:accuracystandard}
\end{table}

In order to prevent our analysis against heavy overfitting we chose to implement cross-validation for all machine learning techniques. We associated randomly 20\% of the training set to be the validation set. We then trained the model with the remaining 80\% of the training set and validating the analysis on the validation set. This is done multiple times and averaged.

\textit{
Explain your whole approach (you can include a block diagram showing the steps in your process).
\begin{itemize}
\item What methods/algorithms, why were the methods chosen.
\item What evaluation methodology (cross CV, etc.).
\end{itemize}
}

\section{Results}

\textit{
Summarize the results of the experiments without discussing their implications.
\begin{itemize}
\item Include both performance measures (accuracy and LogLoss).
\item How does it perform on kaggle compared to the train data.
\item Include a confusion matrix.
\end{itemize}
}

\section{Discussion/Conclusions}

\textit{
Interpret and explain your results
\begin{itemize}
\item Discuss the relevance of the performance measures (accuracy and LogLoss) for
imbalanced multiclass datasets.
\item How the results relate to the literature.
\item Suggestions for future research/improvement.
\item Did the study answer your questions?
\end{itemize}
}

\section{References}

\textit{List of all the references cited in the document
}

\section{Appendices}

\textit{Additional information that is not essential to explain your findings, but supports your work. For example, source code, additional images, mathematical derivations, etc.
If you include source code, don’t include the whole code, focus only on the most important parts, for example, a function implementing a specific algorithm
}


\end{document}